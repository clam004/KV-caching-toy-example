{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba90b98-bb13-44b4-b609-b8095794f096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import time\n",
    "    \n",
    "from pico.utils import load_encoder_hparams_and_params\n",
    "from pico.gpt2 import generate, gelu, softmax, layer_norm, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24853542-495d-4ab9-b6c9-76d7575ff006",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens_to_generate = 40\n",
    "tokenizer, hparams, params = load_encoder_hparams_and_params(model_size = \"124M\", models_dir = \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b01d21b-4d4b-4f9f-ace7-a85b2f13b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Alan Turing theorized that computers would one day become\"\n",
    "input_ids = tokenizer.encode(prompt)\n",
    "# make sure we are not surpassing the max sequence length of our model\n",
    "assert len(input_ids) + n_tokens_to_generate < hparams[\"n_ctx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5841c5a2-2733-4d25-9dd1-33c41edb3800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating: 100%|███████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:46<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The process took 46.42891502380371 seconds to complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe computer is also capable of performing calculations that are very similar to the human brain.\\n\\nThe computer is also capable of performing calculations that are very similar to the human brain.\\n\\nThe'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# generate output ids\n",
    "output_ids = generate(input_ids, params, hparams[\"n_head\"], n_tokens_to_generate)\n",
    "# decode the ids back into a string\n",
    "output_text = tokenizer.decode(output_ids)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The process took {elapsed_time} seconds to complete.\")\n",
    "\n",
    "output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee237782-94b6-4b09-be70-31c43886fcbb",
   "metadata": {},
   "source": [
    "https://www.dipkumar.dev/posts/gpt-kvcache/\n",
    "\n",
    "https://github.com/jaymody/picoGPT/pull/7/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "251ca01a-7357-4c5b-808f-f8748955f3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks', 'ln_f', 'wpe', 'wte'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc50c765-2e0c-4cfd-b9b0-fd2d13e12ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff499b14-d0bb-4420-9270-23d21fe42b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['wpe'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d9fd3-ac2c-4b74-8340-9e6828486d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
